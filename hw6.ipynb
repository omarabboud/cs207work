{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q1.\n",
    "\n",
    "Add a __setitem__ to the python linked list implementation from the lecture (this past wednesday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "def __setitem__(self, key, c):\n",
    "    self.insert((key,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "\n",
    "An online mean and standard deviation algorithm.\n",
    "\n",
    "Below is a function to generate a potentially infinite stream of 1-D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import normalvariate, random\n",
    "from itertools import count\n",
    "def make_data(m, stop=None):\n",
    "    for _ in count():\n",
    "        if stop and _ > stop:\n",
    "            break\n",
    "        yield 1.0e09 + normalvariate(0, m*random() )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an implementation of an online mean algorithm..see http://www.johndcook.com/blog/standard_deviation/ and the link to http://www.johndcook.com/blog/2008/09/26/comparing-three-methods-of-computing-standard-deviation/ in-between. (Convince yourselves of the formulas...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def online_mean(iterator):\n",
    "    n = 0\n",
    "    mu = 0\n",
    "    for value in iterator:\n",
    "        n += 1\n",
    "        delta = value - mu\n",
    "        mu = mu + delta/n\n",
    "        yield mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use out generator functions to implement iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000000000.8007792,\n",
       " 1000000001.099089,\n",
       " 1000000005.6191047,\n",
       " 1000000002.3382626,\n",
       " 999999994.9325846,\n",
       " 1000000002.6687838,\n",
       " 1000000000.3893675,\n",
       " 1000000003.1991405,\n",
       " 1000000001.5009574,\n",
       " 999999995.4134774,\n",
       " 999999997.8654048]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = make_data(5, 10)\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1000000000.0383301,\n",
       " 999999999.8608612,\n",
       " 1000000001.9833528,\n",
       " 1000000002.0076723,\n",
       " 1000000001.3045043,\n",
       " 1000000001.6368686,\n",
       " 1000000001.2049081,\n",
       " 1000000000.9359994,\n",
       " 1000000000.8467113,\n",
       " 1000000000.7816591,\n",
       " 1000000000.7046827,\n",
       " 1000000000.5493864,\n",
       " 1000000000.7307124,\n",
       " 1000000000.7744975,\n",
       " 1000000000.5426629,\n",
       " 1000000000.3482492,\n",
       " 1000000000.3119509,\n",
       " 1000000000.7185297,\n",
       " 1000000000.773973,\n",
       " 1000000000.7601937,\n",
       " 1000000000.730617,\n",
       " 1000000000.6295277,\n",
       " 1000000000.6185038,\n",
       " 1000000000.5935628,\n",
       " 1000000000.324125,\n",
       " 1000000000.4020188,\n",
       " 1000000000.4837278,\n",
       " 1000000000.5584495,\n",
       " 1000000000.6277989,\n",
       " 1000000000.6275498,\n",
       " 1000000000.625016,\n",
       " 1000000000.5676911,\n",
       " 1000000000.6185404,\n",
       " 1000000000.6680492,\n",
       " 1000000000.7856728,\n",
       " 1000000000.7785002,\n",
       " 1000000000.7797543,\n",
       " 1000000000.899072,\n",
       " 1000000001.0228016,\n",
       " 1000000000.9715472,\n",
       " 1000000000.8380038,\n",
       " 1000000000.9180142,\n",
       " 1000000000.7241408,\n",
       " 1000000000.727064,\n",
       " 1000000000.7324262,\n",
       " 1000000000.8321835,\n",
       " 1000000000.6961212,\n",
       " 1000000000.7164052,\n",
       " 1000000000.713149,\n",
       " 1000000000.7763648,\n",
       " 1000000000.7603233,\n",
       " 1000000000.7891906,\n",
       " 1000000000.8948945,\n",
       " 1000000000.8704529,\n",
       " 1000000000.8772938,\n",
       " 1000000000.7842323,\n",
       " 1000000000.8331355,\n",
       " 1000000000.7981582,\n",
       " 1000000000.8045312,\n",
       " 1000000000.7418499,\n",
       " 1000000000.7258525,\n",
       " 1000000000.736535,\n",
       " 1000000000.7271413,\n",
       " 1000000000.7432586,\n",
       " 1000000000.7345226,\n",
       " 1000000000.7593561,\n",
       " 1000000000.6947396,\n",
       " 1000000000.6569296,\n",
       " 1000000000.7614439,\n",
       " 1000000000.7500646,\n",
       " 1000000000.7532257,\n",
       " 1000000000.7488868,\n",
       " 1000000000.740074,\n",
       " 1000000000.7267115,\n",
       " 1000000000.7190777,\n",
       " 1000000000.7000251,\n",
       " 1000000000.6788527,\n",
       " 1000000000.6636341,\n",
       " 1000000000.6658224,\n",
       " 1000000000.6707078,\n",
       " 1000000000.6595924,\n",
       " 1000000000.7692205,\n",
       " 1000000000.7750958,\n",
       " 1000000000.7595421,\n",
       " 1000000000.7462204,\n",
       " 1000000000.6935289,\n",
       " 1000000000.6366457,\n",
       " 1000000000.5923412,\n",
       " 1000000000.5975246,\n",
       " 1000000000.6113774,\n",
       " 1000000000.563325,\n",
       " 1000000000.573694,\n",
       " 1000000000.6245894,\n",
       " 1000000000.6083086,\n",
       " 1000000000.5936401,\n",
       " 1000000000.6131835,\n",
       " 1000000000.601796,\n",
       " 1000000000.6303853,\n",
       " 1000000000.6149668,\n",
       " 1000000000.6252815,\n",
       " 1000000000.6102818]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = online_mean(make_data(5, 100))\n",
    "print(type(g))\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "Implement the standard deviation algorithm as a generator function as\n",
    "\n",
    "```python\n",
    "def online_mean_dev(iterator):\n",
    "    BLA BLA\n",
    "    if n > 1:\n",
    "        stddev = math.sqrt(dev_accum/(n-1))\n",
    "        yield (n, value, mu, stddev)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def online_mean_dev(iterator):\n",
    "    #initialize\n",
    "    std = 0\n",
    "    m = 0\n",
    "    n = 0\n",
    "    #iterate through the iterator\n",
    "    for item in iterator:\n",
    "        m_0 = m\n",
    "        n = n + 1\n",
    "        m = m + ((item - m)/n)\n",
    "        \n",
    "        if n > 1:\n",
    "            std = ((std + ((item - m_0)*(item - m))) / (n - 1))**0.5\n",
    "            yield (n, item, m, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make 100000 element data, and run this iterator on it (imagine running this on a time-series being slowly read from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_stats = online_mean_dev(make_data(5, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "\n",
    "Let's do Anomaly detection. Write a routine `is_ok`:\n",
    "\n",
    "```python\n",
    "def is_ok(level, t)\n",
    "```\n",
    "\n",
    "which takes a tuple like the one yielded by your code above and returns True if the value is inbetween `level`-$\\sigma$ of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_ok(level, t):\n",
    "    #Initialize\n",
    "    item = t[1]\n",
    "    m = t[2]\n",
    "    std = t[3]\n",
    "    #Update\n",
    "    s = level - std\n",
    "    left_bound = m - s\n",
    "    right_bound = m + s\n",
    "    \n",
    "    if(item <= right_bound) and (item >= left_bound):\n",
    "        yield True\n",
    "    else:\n",
    "        yield False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to create a predicate passed through to `itertools.filterfalse` which is then used to obtain an iterator on the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "pred = lambda t: is_ok(5, t)\n",
    "anomalies = filterfalse(pred, data_with_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We materialize the anomalies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(anomalies)#materialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To think of, but not hand in\n",
    "\n",
    "What kinds of anomalies will this algorithm pick up? What kinds would a shorter \"window\" of anomaly detection, like 100 points around the time in question pick? How might you create an algorithm which does window based averaging? (hint: the window size is small compared to the time series size). \n",
    "\n",
    "Finally think a bit of how you might implement all of this in a production environment..remember that data streaming in might get backed up when you handle an anomaly.\n",
    "\n",
    "(Some inspiration might accrue if you look at the docs for `collections.deque`)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
